import requests
import re
import openpyxl
import csv
import os
from openpyxl import Workbook
from config import *
from slackmanger import *
from openpyxl.utils import get_column_letter
import smtplib
from datetime import datetime
from email.mime.multipart import MIMEMultipart
from email.mime.application import MIMEApplication
from email.mime.text import MIMEText

class RealEstateScraper:
    def __init__(self, cookies, headers, apt_list_file):
        self.cookies = cookies
        self.headers = headers
        self.apt_list_file = apt_list_file
        self.apt_data = self.load_apt_data()
        self.email_sender = EMAIL_SENDER
        self.email_smtp_pw = EMAIL_SMTP_PW
    
    def load_apt_data(self):
        apt_data = {}
        with open(self.apt_list_file, mode='r', encoding='utf-8') as file:
            reader = csv.DictReader(file, delimiter=',')
            for row in reader:
                if row['enable'] == 'X':
                    continue
                apt_name = row['ì•„íŒŒíŠ¸ ì´ë¦„']
                apt_idx = row['apt index']
                area_sizes = row['í‰í˜•'].split(',')  # ì—¬ëŸ¬ í‰í˜•ì„ ì‰¼í‘œë¡œ êµ¬ë¶„
                apt_data[apt_idx] = {'apt_name': apt_name, 'area_sizes': [area.strip() for area in area_sizes]}
        return apt_data

    def parse_price(self, price_str):
        # ê³µë°± ì œê±°
        price_str = price_str.replace(" ", "")
        # ì •ê·œì‹ì„ í†µí•´ ê¸ˆì•¡ ë¶„ì„
        match = re.match(r"(\d+)(ì–µ)(\s*(\d{1,3}(,\d{3})*))?", price_str)
        if match:
            billion = int(match.group(1))  # ì–µ ë‹¨ìœ„ ì¶”ì¶œ
            million = match.group(4)  # ë§Œ ë‹¨ìœ„ ì¶”ì¶œ (ì½¤ë§ˆ í¬í•¨)
            price = billion * 100000000  # ì–µ ë‹¨ìœ„ ë³€í™˜
            if million:
                # ì½¤ë§ˆ ì œê±° í›„ ì •ìˆ˜ë¡œ ë³€í™˜
                million = int(million.replace(",", ""))
                price += million * 10000  # ë§Œ ë‹¨ìœ„ ë³€í™˜
            return price
        return 0

    def remove_duplicate_lists(self, data):
        unique_data = []
        for item in data:
            # ì²« ë²ˆì§¸ í•­ëª©ì´ ì´ë¯¸ ìžˆëŠ”ì§€ í™•ì¸
            if not any(
                all(item[i] == existing_item[i] for i in [0, 3, 4, 6, 7, 9]) for existing_item in unique_data
            ):
                unique_data.append(item)
        return unique_data

    def fetch_data(self, apt_idx):
        base_url = f'https://new.land.naver.com/api/articles/complex/{apt_idx}?realEstateType=APT%3AABYG%3AJGC%3APRE&tradeType=B2%3AA1&tag=%3A%3A%3A%3A%3A%3A%3A%3A&rentPriceMin=0&rentPriceMax=900000000&priceMin=0&priceMax=900000000&areaMin=0&areaMax=900000000&oldBuildYears&recentlyBuildYears&minHouseHoldCount&maxHouseHoldCount&showArticle=false&sameAddressGroup=true&minMaintenanceCost&maxMaintenanceCost&priceType=RETAIL&directions=&complexNo=120960&buildingNos=&areaNos=14%3A1%3A3%3A2%3A4%3A5%3A7%3A8%3A6%3A9%3A10%3A11%3A15%3A12&type=list&order=rank'

        all_articles = []
        page = 1
        while True:
            response = requests.get(f"{base_url}&page={page}", cookies=self.cookies, headers=self.headers)
            if response.status_code != 200:
                break
            
            data = response.json()
            articles = data.get('articleList', [])

            for article in articles:
                str_area2 = str(article.get('area2'))
                if article.get('tradeTypeName') == 'ë§¤ë§¤' and str_area2 in self.apt_data[apt_idx]['area_sizes']:
                    all_articles.append([
                        article.get('articleName', ''),
                        article.get('realEstateTypeName', ''),
                        article.get('tradeTypeName', ''),
                        article.get('dealOrWarrantPrc', ''),
                        article.get('areaName', ''),
                        article.get('area2', ''),
                        article.get('floorInfo', ''),
                        article.get('direction', ''),
                        article.get('realtorName', ''),
                        article.get('buildingName', ''),
                        ', '.join(article.get('tagList', [])),
                        article.get('articleFeatureDesc', ''),
                    ])

            if not data.get('isMoreData', False):
                break
            
            page += 1
        
        all_articles.sort(key=lambda x: self.parse_price(x[3]))  # Sort by price
        all_articles = self.remove_duplicate_lists(all_articles)
        
        return all_articles

    def save_data(self, all_articles):
        wb = Workbook()
        
        # Loop through each apartment's data and create a new sheet for each
        for apt_idx, data in self.apt_data.items():
            ws = wb.create_sheet(title=f"{data['apt_name']}")
            
            # Set column headers
            headers = [
                'Article Name', 'Real Estate Type', 'Trade Type', 'Price', 'Area Name',
                'Area2', 'Floor', 'Direction', 'Realtor Name', 'Building Name', 'Tags', 'Features'
            ]
            for col_num, header in enumerate(headers, 1):
                col_letter = get_column_letter(col_num)
                ws[f'{col_letter}1'] = header
            
            # Add article data
            apt_articles = [article for article in all_articles if str(article[0]) in data['apt_name']]  # Filter articles by area2

            for row_num, article in enumerate(apt_articles, 2):
                for col_num, value in enumerate(article, 1):
                    col_letter = get_column_letter(col_num)
                    ws[f'{col_letter}{row_num}'] = value
        
        # Remove the default sheet created with the workbook
        del wb['Sheet']

        # íŠ¹ì • í¬ë§·ìœ¼ë¡œ ì¶œë ¥
        formatted_date = datetime.now().strftime("%Y-%m-%d")

        file_name = formatted_date + "_" + APT_LIST_OUTPUT
        # output í´ë” ê²½ë¡œ ì¶”ê°€
        output_directory = os.path.join(os.path.dirname(os.path.abspath(__file__)), "output")

        # output í´ë”ê°€ ì—†ìœ¼ë©´ ìƒì„±
        if not os.path.exists(output_directory):
            os.makedirs(output_directory)

        # íŒŒì¼ì„ output í´ë” ì•ˆì— ì €ìž¥
        file_path = os.path.join(output_directory, file_name)
        wb.save(file_path)
        print(f"Data saved to {file_name}.")

        return file_path

    def send_email(self, subject, body, to_email, attachment_path):
        from_email = self.email_sender
        from_password = self.email_smtp_pw

        msg = MIMEMultipart()
        msg['From'] = from_email
        msg['To'] = to_email
        msg['Subject'] = subject
        msg.attach(MIMEText(body, 'plain'))

        with open(attachment_path, "rb") as attachment:
            part = MIMEApplication(attachment.read(), Name=attachment_path)
            part['Content-Disposition'] = f'attachment; filename="{attachment_path}"'
            msg.attach(part)

        try:
            with smtplib.SMTP('smtp.gmail.com', 587) as server:
                server.starttls()
                server.login(from_email, from_password)
                server.sendmail(from_email, to_email, msg.as_string())
                print(f"Email sent to {to_email}.")
        except Exception as e:
            print(f"Failed to send email: {e}")
    
    def format_apt_data(self, apt_name, apt_data = list()):
        white_check = "âœ…"
        header = f'{white_check} {apt_name} {white_check}\n'
        # í•„ë“œë³„ ìµœëŒ€ ê¸¸ì´ë¥¼ ì €ìž¥í•  ë¦¬ìŠ¤íŠ¸
        max_lengths = [0] * 6  # 6ì€ `/`ë¡œ êµ¬ë¶„ë˜ëŠ” í•„ë“œì˜ ê°œìˆ˜

        # ê° í•„ë“œì˜ ìµœëŒ€ ê¸¸ì´ ê³„ì‚°
        for data in apt_data:
            fields = [data[3], data[5], data[6], data[7], data[9], data[11]]
            for i, field in enumerate(fields):
                max_lengths[i] = max(max_lengths[i], len(str(field)))

        formatted_str = ''
        # ë°ì´í„°ë¥¼ í¬ë§·íŒ…í•˜ì—¬ ì¶œë ¥ ë¬¸ìžì—´ ìƒì„±
        for idx, data in enumerate(apt_data):
            fields = [data[3], data[5], data[6], data[9], data[7], data[11]]
            formatted_fields = [
                str(field).ljust(max_lengths[i]) for i, field in enumerate(fields)
            ]
            formatted_str += f'{str("ðŸ“Œ").ljust(2)} {" | ".join(formatted_fields)}\n\n'
        
        formatted_str += '\n'

        return header + formatted_str

if __name__ == '__main__':
    print(os.path.join(os.getcwd(), APT_LIST_INPUT))
    scraper = RealEstateScraper(REAL_STATE_DATA_COOKIE, REAL_STATE_DATA_HEADER, os.path.join(os.path.dirname(os.path.abspath(__file__)), APT_LIST_INPUT))
    slack = SlackManager(SLACK_CHANNEL_ID, SLACK_OAUTH_TOKEN)
    # Fetch and save data for each apartment index
    all_articles = []
    for apt_idx, data in scraper.apt_data.items():
        apt_articles = scraper.fetch_data(apt_idx)
        all_articles.extend(apt_articles)

    file_path = scraper.save_data(all_articles)
    slack.upload_file(file_path)

    for apt_idx, apt_data in scraper.apt_data.items():
        my_data = []
        my_data.extend([data for data in all_articles 
                        if str(apt_data['apt_name']) == data[0] and
                        (((data[6].split("/")[0].isdigit() and int(data[6].split("/")[0]) >= LOWER_FLOOR_LIMIT) or 
                          ((data[6].split("/")[0] == "ì¤‘") or (data[6].split("/")[0] == "ê³ "))) and
                        (data[6].split("/")[0] != "ì €"))]) # ì €ì¸µ ì œì™¸
        message = scraper.format_apt_data(str(apt_data['apt_name']), my_data[:SLACK_LIST_LIMIT])

        print(message)
        slack.send_message(message)
    '''
    # Send the excel file as an email attachment
    scraper.send_email(
        subject="Real Estate Data for All Apartments",
        body="Please find the attached real estate data for all apartments.",
        to_email=EMAIL_RECEIVER,
        attachment_path=excel_file
    )
    '''
